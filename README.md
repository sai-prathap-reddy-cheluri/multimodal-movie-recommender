# ğŸ¬ Multimodal Movie Recommender â€” Data â†’ Baseline â†’ Hybrid

A fast, modern pipeline for building a **nextâ€‘gen movie recommender**.
Start with a solid **data foundation**, then ship a **dense retriever + light reranker** baseline, and finally upgrade to **hybrid retrieval (dense + BM25) with languageâ€‘aware ranking**.

> **Attribution:** This product uses the TMDb API but is not endorsed or certified by TMDb.

---

## âœ¨ Features

- **Recursive windowing** to bypass TMDbâ€™s 10k results/query cap
- **Async credits backfill** (runtime, full cast, directors) with controlled concurrency
- **Typed Parquet** + optional partitioning (fast loading, analyticsâ€‘friendly)
- **Baseline recommender**: embeddings + FAISS + light rerank (blend / CE / MMR)
- **Hybrid retrieval**: dense (embeddings) + sparse (BM25) fused via **RRF**
- **Languageâ€‘aware ranking**: autoâ€‘detect language intent in query; **soft boost** or **hard filter**
- **Streamlit demo** (GPUâ€‘aware on Windows 11) and **tiny offline eval**

---

## ğŸ—‚ï¸ Project Layout

```
â”œâ”€ data/
â”‚  â””â”€ processed/
â”‚     â”œâ”€ movies.parquet                # full typed dataset
â”‚     â”œâ”€ movies_parquet/               # partitioned by year
â”‚     â”œâ”€ movies_sample.parquet         # small sample kept in Git
â”‚     â””â”€ artifacts/
â”‚        â”œâ”€ text.index                 # FAISS index (cosine/IP)
â”‚        â”œâ”€ text_idmap.parquet         # rowid â†” movie_id
â”‚        â””â”€ search_payload.parquet     # lean fields for search/rerank
â”œâ”€ reports/
â”‚  â”œâ”€ data_profile.json
â”‚  â””â”€ checksums.txt
â”œâ”€ notebooks/
â”‚  â””â”€ 01_eda_movies.ipynb              # portfolioâ€‘style EDA
â”œâ”€ src/
â”‚  â”œâ”€ config.py                        # reads .env; paths; device detection
â”‚  â”œâ”€ download_dataset.py              # Gradio UI to fetch CSVs
â”‚  â”œâ”€ tmdb_api_test.py                 # quick API smoke test
â”‚  â”œâ”€ data/
â”‚  â”‚  â””â”€ data_preparation.py           # CSV â†’ Parquet â†’ sample â†’ reports
â”‚  â”œâ”€ recsys/
â”‚  â”‚  â”œâ”€ build_text_index.py           # Step 3A (doc builder + embeddings + FAISS)
â”‚  â”‚  â”œâ”€ search_and_rerank.py          # Step 3B + Step 4 (retrieval, CE, MMR, HYBRID)
â”‚  â”‚  â”œâ”€ eval_proxy.py                 # Step 3C proxy metrics
â”‚  â”‚  â”œâ”€ hybrid_sparse.py              # BM25 retriever
â”‚  â”‚  â””â”€ hybrid_fusion.py              # RRF combiner
â”‚  â””â”€ app/
â”‚     â””â”€ demo.py                       # Streamlit demo
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ”‘ Prerequisites

- Python **3.10+**
- A free TMDb API key â†’ https://www.themoviedb.org/settings/api
- (Optional but recommended) NVIDIA GPU on **Windows 11** with CUDA for faster encoders

Create a **`.env`** in the project root:

```ini
TMDB_API_KEY=YOUR_TMDB_KEY_HERE

# Hugging Face (avoid 429s)
HUGGING_FACE_HUB_TOKEN=hf_xxx
HF_HOME=.hf_cache

# Models / perf (override if desired)
EMBED_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
CROSS_ENCODER_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2
ST_FP16=1
```

---

## ğŸ§° Setup

```bash
# create & activate venv (Windows PowerShell)
python -m venv venv
.\venv\Scripts\activate

# macOS / Linux
python -m venv venv
source venv/bin/activate

# install CUDA PyTorch (Windows with CUDA 12.1; adjust if needed)
pip install --upgrade --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio

# install project deps
pip install -r requirements.txt
```

### âœ… Verify your TMDb API setup

```bash
# from repo root
python -m src.tmdb_api_test
```

---

## ğŸš€ Download a Dataset (Gradio UI)

```bash
python -m src.download_dataset
```
- Choose a date range (uses recursive windowing under-the-hood)
- Toggle **Include adult (18+)** if relevant
- **Concurrency** 12â€“20 is a good start
- Outputs CSV under `data/`

### ğŸ” Backfill Missing Credits (CLI)

```bash
python -m src.scripts.backfill_credits --csv data/movies_YYYY-MM-DD_YYYY-MM-DD.csv --concurrency 12 --batch-size 800
```
What it does:
- Reads CSV
- Finds rows where **both** actors & directors are blank
- Fetches credits with retries + exponential backoff + jitter
- Writes progress back to the same CSV each batch (safe stop/resume)

---

## ğŸ§± Step 1 â€” Intake & Validation (CSV â†’ Parquet)

Convert raw CSV â†’ **typed Parquet**, plus a small sample and integrity reports.

```bash
python src/data/prepare_ds_release.py data/movies_2020-01-01_2025-08-08.csv
```

**Outputs:**
- `data/processed/movies.parquet`
- `data/processed/movies_parquet/` (partitioned)
- `data/processed/movies_sample.parquet`
- `reports/data_profile.json`, `reports/checksums.txt`

---

## ğŸ“Š Step 2 â€” Exploratory Data Analysis (EDA)

Open `notebooks/01_eda_movies.ipynb` for a compact EDA:
- Year trend ğŸ—“ï¸, Runtime â±ï¸
- Language & Genre mix ğŸŒ
- Popularity skew ğŸ“ˆ
- Missingness heatmap ğŸ§¼
- Poster gallery ğŸï¸

**What it tells us:**
- Strong recent coverage â†’ timeâ€‘based splits
- Popularity is skewed â†’ add semantic retrieval to reduce bias
- Missingness is localized â†’ impute/skip perâ€‘feature

---

## âš™ï¸ Step 3 â€” Baseline â€œnextâ€‘genâ€ recommender (embeddings + light rerank)

Build a fast, modern baseline: **dense retrieval** over **rich docs** + tiny reranker.

### 3A â€” Build the text index
```bash
python -m src.recsys.build_text_index
```
Creates:
- `data/processed/artifacts/text.index` (FAISS, cosine/IP)
- `data/processed/artifacts/text_idmap.parquet`
- `data/processed/artifacts/search_payload.parquet` (includes the **doc**: title Â· overview Â· top cast/crew Â· genres Â· **language** Â· year)

### 3B â€” Search + rerank (CLI)
```bash
# Blend (retrieval + recency + popularity)
python -m src.recsys.search_and_rerank "smart heist thriller set in Europe" --k 20 --method blend

# Retrieval only (no rerank)
python -m src.recsys.search_and_rerank "lonely space survival drama" --k 20 --method retrieval

# Crossâ€‘encoder rerank (small; uses GPU if available)
python -m src.recsys.search_and_rerank "neoâ€‘noir crime with witty dialogue" --k 20 --method ce

# MMR diversity (good default Î»â‰ˆ0.2â€“0.3)
python -m src.recsys.search_and_rerank "cozy holiday romcom" --k 20 --method mmr --mmr_lambda 0.3
```

### 3C â€” Tiny proxy eval
```bash
python -m src.recsys.eval_proxy --k 10 --sample_n 200 --method blend
```
Outputs CSV + summary JSON in `artifacts/`.

### 3D â€” Streamlit demo
```bash
streamlit run src/app/demo.py
```
Use the sidebar to:
- Enter a taste query
- Choose **method** (blend / retrieval / ce / mmr / **hybrid**)
- Set **Topâ€‘K**, **MMR Î»** (for MMR), and **Min vote_count**

---

## ğŸ§ª Step 4 â€” Hybrid retrieval (dense + BM25) with languageâ€‘aware ranking

**Why:** exact names/franchises/misspellings + strong semantic recall is the 2025 default.
**How:** fuse **dense (FAISS)** and **sparse (BM25)** with **RRF**; detect language intent and **boost** or **hardâ€‘keep** that language.

### Use it
```bash
# RRF fusion + soft language boost (default)
python -m src.recsys.search_and_rerank "malayalam thriller" --method hybrid --k 20

# Hard language preference (keep Malayalam first, then topâ€‘up)
python -m src.recsys.search_and_rerank "malayalam thriller" --method hybrid --k 20 --lang_policy auto-hard
```

**Knobs:**
- `--hybrid_dense_k / --hybrid_sparse_k` â€“ candidate pool sizes (default 500/500)
- `--rrf_k` â€“ RRF constant (typical 50â€“100; default 60)
- `--w_dense / --w_sparse` â€“ source weights (default 1.0/1.0)
- `--lang_policy` â€“ `off | auto-soft | auto-hard`

**Whatâ€™s under the hood:**
- `hybrid_sparse.py` builds an inâ€‘memory **BM25** over `doc`
- `search_and_rerank.py` returns **rowid** from FAISS; hybrid uses RRF on rowids
- Language intent is **dataâ€‘driven** (codes + spoken names discovered from payload)
- Query is augmented with â€œ**Language: <Name>**â€ so both dense & BM25 see it
- Policy: **soft boost** (multiply scores) or **hard keep** (filter/topâ€‘up)

---

## ğŸ” How to search (good queries)

**Recipe:** `[genre] + [vibe] + [hook/theme] + [setting/locale] + [constraints]`

Examples (paste asâ€‘is):
- â€œslowâ€‘burn sciâ€‘fi about isolation in spaceâ€
- â€œIndian Malayalam investigative thriller after 2020â€
- â€œlike â€˜Drishyamâ€™, tight family crime with twistsâ€
- â€œanime comingâ€‘ofâ€‘age with music and friendshipâ€
- â€œTamil neoâ€‘noir crime in Chennaiâ€
- â€œFrench heist comedy 2000sâ€

**Tips:**
- Prefer **natural language** over boolean syntax
- For variety: `--method mmr --mmr_lambda 0.25`
- For exact names/franchises: `--method hybrid`
- If results feel too niche: raise **Min vote_count** in the demo

---

## ğŸ§© Troubleshooting

- **HF 429 / auth** â†’ add `HUGGING_FACE_HUB_TOKEN` to `.env` or preâ€‘download models; set `HF_HOME=.hf_cache`
- **FAISS error: `n, d = x.shape`** â†’ ensure query vector is **(1, d) float32** (already handled in code)
- **pd.NA slicing** â†’ code uses NAâ€‘safe helpers; rebuild if you changed doc logic
- **Streamlit import error** â†’ run from repo root or use the path bootstrap in `demo.py`
- **Few results with MMR + min votes** â†’ set min votes to 0 or use the â€œtopâ€‘upâ€ filter; increase MMR pool

---

## ğŸ§­ Roadmap

- Poster caching on demand
- **Hybrid by default** in demo, with entityâ€‘aware boosts (actors/directors)
- Explanations (â€œBecause you likedâ€¦ / shares actor Y / genre Zâ€)
- Personalization (seed titles â†’ user vector)
- FastAPI + Docker for deployment
- Multimodal ranking (CLIP poster embeddings + text)

---

## ğŸ“œ License

MIT

